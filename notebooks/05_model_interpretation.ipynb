{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Interpretation & Validation - Injury Risk Predictor\n",
        "\n",
        "This notebook interprets the trained model and validates it against sports science research.\n",
        "\n",
        "## Steps:\n",
        "1. Load trained model and data\n",
        "2. Feature importance analysis\n",
        "3. SHAP values for explainability\n",
        "4. Partial dependence plots\n",
        "5. Error analysis\n",
        "6. Validation against research\n",
        "7. Cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append('..')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from src.ml.features import engineer_features_for_dataset\n",
        "from src.ml.preprocessing import (\n",
        "    handle_missing_values,\n",
        "    encode_categorical_features,\n",
        "    split_data_by_time,\n",
        "    scale_features\n",
        ")\n",
        "from src.ml.train import load_model, load_scaler\n",
        "from src.ml.interpretation import (\n",
        "    plot_feature_importance,\n",
        "    calculate_shap_values,\n",
        "    plot_shap_summary,\n",
        "    plot_partial_dependence,\n",
        "    analyze_errors,\n",
        "    validate_against_research,\n",
        "    print_validation_report\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Model and Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data\n",
        "training_logs = pd.read_csv('../data/training_logs.csv')\n",
        "\n",
        "# Engineer features\n",
        "df = engineer_features_for_dataset(training_logs)\n",
        "df = handle_missing_values(df, method='forward_fill')\n",
        "df, encoders = encode_categorical_features(df)\n",
        "\n",
        "# Split data\n",
        "X_train, y_train, X_val, y_val, X_test, y_test = split_data_by_time(\n",
        "    df,\n",
        "    train_weeks=(1, 14),\n",
        "    val_weeks=(15, 19),\n",
        "    test_weeks=(20, 24)\n",
        ")\n",
        "\n",
        "# Try to load scaler and model\n",
        "scaler = None\n",
        "model = None\n",
        "model_name = None\n",
        "\n",
        "try:\n",
        "    scaler = load_scaler('../models')\n",
        "    print(\"✓ Loaded scaler\")\n",
        "except FileNotFoundError:\n",
        "    print(\"⚠ No scaler found. Training a new scaler...\")\n",
        "    # Train a new scaler if not found\n",
        "    X_train_scaled, scaler = scale_features(X_train, fit=True, scaler_type='standard')\n",
        "    X_val_scaled, _ = scale_features(X_val, fit=False, scaler=scaler)\n",
        "    X_test_scaled, _ = scale_features(X_test, fit=False, scaler=scaler)\n",
        "    print(\"✓ Created new scaler\")\n",
        "else:\n",
        "    # Scale features with loaded scaler\n",
        "    X_train_scaled, _ = scale_features(X_train, fit=False, scaler=scaler)\n",
        "    X_val_scaled, _ = scale_features(X_val, fit=False, scaler=scaler)\n",
        "    X_test_scaled, _ = scale_features(X_test, fit=False, scaler=scaler)\n",
        "\n",
        "# Load best model (adjust name based on what was saved)\n",
        "# Try common model names\n",
        "model_names = ['random_forest', 'Random Forest', 'xgboost', 'XGBoost', 'logistic_regression', 'Logistic Regression']\n",
        "model = None\n",
        "model_name = None\n",
        "\n",
        "for name in model_names:\n",
        "    try:\n",
        "        model = load_model(name, '../models')\n",
        "        model_name = name\n",
        "        print(f\"✓ Loaded model: {name}\")\n",
        "        break\n",
        "    except (FileNotFoundError, Exception):\n",
        "        continue\n",
        "\n",
        "if model is None:\n",
        "    print(\"\\n⚠ Warning: No saved model found.\")\n",
        "    print(\"To train a model, run: python3 scripts/quick_train.py\")\n",
        "    print(\"Or use the 04_model_training.ipynb notebook\")\n",
        "    print(\"\\nThe interpretation cells below will be skipped until a model is trained.\")\n",
        "else:\n",
        "    print(f\"\\n✓ Model loaded successfully!\")\n",
        "    print(f\"Model type: {type(model).__name__}\")\n",
        "    print(f\"Test set size: {len(X_test_scaled)}\")\n",
        "    print(f\"Training set size: {len(X_train_scaled)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Feature Importance Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot feature importance\n",
        "if model is not None:\n",
        "    feature_importance_df = plot_feature_importance(\n",
        "        model,\n",
        "        X_train_scaled.columns.tolist(),\n",
        "        top_n=15,\n",
        "        save_path='../outputs/feature_importance.png'\n",
        "    )\n",
        "    \n",
        "    print(\"\\nTop 15 Most Important Features:\")\n",
        "    print(feature_importance_df.head(15).to_string(index=False))\n",
        "    \n",
        "    # Validate: ACWR should be in top 3\n",
        "    top_3_features = feature_importance_df.head(3)['feature'].tolist()\n",
        "    if 'acwr' in top_3_features:\n",
        "        print(\"\\n✓ Validation PASSED: ACWR is in top 3 features\")\n",
        "    else:\n",
        "        print(f\"\\n⚠ Validation WARNING: ACWR is not in top 3 (top 3: {top_3_features})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. SHAP Values (Advanced Explainability)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate SHAP values\n",
        "if model is not None:\n",
        "    shap_results = calculate_shap_values(model, X_test_scaled, max_samples=100)\n",
        "    \n",
        "    if shap_results:\n",
        "        print(\"✓ SHAP values calculated\")\n",
        "        \n",
        "        # Plot SHAP summary\n",
        "        plot_shap_summary(\n",
        "            shap_results['shap_values'],\n",
        "            shap_results['X_sample'],\n",
        "            top_n=15,\n",
        "            save_path='../outputs/shap_summary.png'\n",
        "        )\n",
        "        \n",
        "        print(\"\\nSHAP values show how each feature contributes to predictions.\")\n",
        "        print(\"Red = increases injury risk, Blue = decreases injury risk\")\n",
        "    else:\n",
        "        print(\"SHAP values not available (install with: pip install shap)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Partial Dependence Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot partial dependence for key features\n",
        "if model is not None:\n",
        "    key_features = ['acwr', 'strain', 'week_over_week_change', 'monotony']\n",
        "    \n",
        "    for feature in key_features:\n",
        "        if feature in X_test_scaled.columns:\n",
        "            plot_partial_dependence(\n",
        "                model,\n",
        "                X_test_scaled,\n",
        "                feature,\n",
        "                save_path=f'../outputs/partial_dependence_{feature}.png'\n",
        "            )\n",
        "            print(f\"✓ Created partial dependence plot for {feature}\")\n",
        "    \n",
        "    print(\"\\nPartial dependence plots show how injury risk changes with each feature.\")\n",
        "    print(\"For ACWR, we expect risk to increase above 1.3 and especially above 1.5.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Error Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze prediction errors\n",
        "if model is not None:\n",
        "    y_test_pred = model.predict(X_test_scaled)\n",
        "    \n",
        "    error_analysis = analyze_errors(\n",
        "        y_test.values,\n",
        "        y_test_pred,\n",
        "        X_test_scaled,\n",
        "        X_test_scaled.columns.tolist()\n",
        "    )\n",
        "    \n",
        "    print(\"\\nError Analysis:\")\n",
        "    print(f\"Total errors: {error_analysis['total_errors']} ({error_analysis['error_rate']:.2%})\")\n",
        "    print(f\"False positives (false alarms): {error_analysis['false_positives']}\")\n",
        "    print(f\"False negatives (missed injuries): {error_analysis['false_negatives']}\")\n",
        "    \n",
        "    # Compare feature distributions\n",
        "    if 'false_negative_features' in error_analysis:\n",
        "        print(\"\\nFeatures for False Negatives (missed injuries):\")\n",
        "        fn_features = error_analysis['false_negative_features']\n",
        "        for feature in ['acwr', 'strain', 'week_over_week_change']:\n",
        "            if feature in fn_features:\n",
        "                print(f\"  {feature}: {fn_features[feature]:.3f}\")\n",
        "    \n",
        "    if 'false_positive_features' in error_analysis:\n",
        "        print(\"\\nFeatures for False Positives (false alarms):\")\n",
        "        fp_features = error_analysis['false_positive_features']\n",
        "        for feature in ['acwr', 'strain', 'week_over_week_change']:\n",
        "            if feature in fp_features:\n",
        "                print(f\"  {feature}: {fp_features[feature]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Validation Against Research"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validate model predictions against sports science research\n",
        "if model is not None:\n",
        "    # Use test set for validation\n",
        "    validations = validate_against_research(\n",
        "        model,\n",
        "        X_test_scaled,\n",
        "        X_test_scaled.columns.tolist()\n",
        "    )\n",
        "    \n",
        "    print_validation_report(validations)\n",
        "    \n",
        "    # Summary\n",
        "    passed = sum(1 for k, v in validations.items() if k.endswith('_threshold') or k.endswith('_spike') or k.endswith('_relationship') and v is True)\n",
        "    total = sum(1 for k, v in validations.items() if k.endswith('_threshold') or k.endswith('_spike') or k.endswith('_relationship') and v is not None)\n",
        "    \n",
        "    print(f\"\\nValidation Summary: {passed}/{total} checks passed\")\n",
        "    if passed == total:\n",
        "        print(\"✓ Model predictions align with sports science research!\")\n",
        "    else:\n",
        "        print(\"⚠ Some validations failed - review model and features\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
